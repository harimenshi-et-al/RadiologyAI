import torch
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import time
import os
import torch.nn.functional as F

from sklearn.utils.class_weight import compute_class_weight
from sklearn.metrics import confusion_matrix
from torch.utils.data import DataLoader, WeightedRandomSampler
from torchvision import datasets, transforms, models
from PIL import Image
from torchcam.methods import SmoothGradCAMpp
from torchcam.utils import overlay_mask
from torchvision.transforms.functional import to_pil_image
from torchvision.models import densenet121, DenseNet121_Weights

# ----------------< Colab Environment Module >--------------------------------------------------------------------------
# "#" this section out whenever working on PyCharm
from google.colab import drive
drive.mount('/content/drive')
data_dir = "/content/drive/MyDrive/Radiology_v3"
local_data_dir = "/content/Radiology_v3_local"


if not os.path.exists(local_data_dir):
    print("Copying dataset to local Colab storage (one-time per session)...")
    import shutil
    shutil.copytree(data_dir, local_data_dir, ignore=shutil.ignore_patterns('checkpoints', '*.pth'))
    print("Dataset copied successfully!")
else:
    print("Using existing local dataset copy")

# ----------------< Environment Module >--------------------------------------------------------------------------------

def main():
    # Device configuration - AUTOMATIC GPU/CPU SELECTION
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    if torch.cuda.is_available():
        print(f"GPU: {torch.cuda.get_device_name(0)}")
        print(f"VRAM Available: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB")
    else:
        print("CUDA not available, using CPU")

    data_dir = "/content/drive/MyDrive/Radiology_v3" # Google Colab's mode
    checkpoint_dir = "/content/drive/MyDrive/Radiology_v3/checkpoints" # Google Colab's mode
    os.makedirs(checkpoint_dir, exist_ok=True)
    start_time = time.time()

    train_transform = transforms.Compose([
        transforms.RandomResizedCrop(256, scale=(0.7, 1.0)),
        transforms.RandomHorizontalFlip(p=0.5),
        transforms.RandomRotation(20),
        transforms.ColorJitter(brightness=0.2, contrast=0.3, saturation=0.2),
        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),
        transforms.GaussianBlur(3, sigma=(0.1, 2.0)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
    ])

    val_transform = transforms.Compose([transforms.Resize((256, 256)), transforms.ToTensor(), transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
    ])

    # Apply them
    train_dataset = datasets.ImageFolder(f"{data_dir}/train", transform=train_transform)
    test_dataset = datasets.ImageFolder(f"{data_dir}/test", transform=val_transform)
    val_dataset = datasets.ImageFolder(f"{data_dir}/val", transform=val_transform)

    print("Classes:", train_dataset.classes)
    class_names = train_dataset.classes
    num_classes = len(class_names)

    print("Class distribution:")
    for i, class_name in enumerate(class_names):
      count = sum(1 for t in train_dataset.targets if t == i)
      print(f"  {class_name}: {count} ({count/len(train_dataset)*100:.1f}%)")


    #varibalistic weight calculation and optimizatoin
    y_train_indices = train_dataset.targets
    class_weights = compute_class_weight(
        class_weight='balanced',
        classes=np.unique(y_train_indices),
        y=y_train_indices
    )
    weights = torch.tensor(class_weights, dtype=torch.float)

    sample_weights = [weights[t] for t in train_dataset.targets]
    sampler = WeightedRandomSampler(sample_weights, len(sample_weights), replacement=True)

    # DataLoader with pin_memory only if using CUDA
    pin_memory = torch.cuda.is_available()
    train_loader = DataLoader(train_dataset, batch_size=32, sampler=sampler, num_workers=0, pin_memory=pin_memory)
    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=0, pin_memory=pin_memory)
    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

    # ----------------< Setup Module >--------------------------------------------------------------------------------------
    model = densenet121(weights=None)
    num_ftrs = model.classifier.in_features
    model.classifier = nn.Sequential(
        nn.Dropout(0.5), #was 0.2 and now changed for fine tuning
        nn.Linear(num_ftrs, num_classes)
    )
    model = model.to(device)

    criterion = nn.CrossEntropyLoss(label_smoothing=0.15)
    optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, cooldown=2, factor=0.1)

    # ----------------< Save States >---------------------------------------------------------------------------------------
    checkpoint_path = f"{checkpoint_dir}/radiology_model_checkpoint.pth"
    best_model_path = f"{checkpoint_dir}/best_model.pth"
    start_epoch = 0
    if os.path.exists(checkpoint_path):
        checkpoint = torch.load(checkpoint_path, map_location=device)
        model.load_state_dict(checkpoint['model_state_dict'])
        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        start_epoch = checkpoint['epoch'] + 1
        print(f"Resuming from epoch {start_epoch}")

    # ----------------< Early Stopping Module >-------------------------------------------------------------------------
    best_val_loss = float('inf')
    patience_counter = 0
    patience = 15

    # ----------------< Training Module >-------------------------------------------------------------------------------
    num_epochs = 15
    for epoch in range(start_epoch, num_epochs):
        model.train()
        running_loss = 0.0
        for inputs, labels in train_loader:
            inputs, labels = inputs.to(device), labels.to(device)  # Changed from .to("cuda")
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            running_loss += loss.item() * inputs.size(0)

        epoch_loss = running_loss / len(train_loader.dataset)

        model.eval()
        val_loss = 0.0
        correct = 0
        total = 0

        with torch.no_grad():
            for inputs, labels in val_loader:
                inputs, labels = inputs.to(device), labels.to(device)
                outputs = model(inputs)
                loss = criterion(outputs, labels)
                val_loss += loss.item() * inputs.size(0)

                # Calculate Accuracy
                _, predicted = torch.max(outputs, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()

        avg_val_loss = val_loss / len(val_loader.dataset)
        val_accuracy = 100 * correct / total

        scheduler.step(avg_val_loss)

        # Loss and Accuracy interface developer interfac
        print(f"Epoch {epoch + 1}/{num_epochs}")
        print(f"Train Loss: {epoch_loss:.4f} | Val Loss: {avg_val_loss:.4f} | Val Acc: {val_accuracy:.2f}%")

        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            patience_counter = 0
            torch.save({'epoch': epoch, 'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict(), 'loss': epoch_loss}, best_model_path)
        else:
            patience_counter += 1
            if patience_counter >= patience:
                print(f"No major improvement observed, early stopping at epoch: {epoch + 1}. Best val loss: {best_val_loss:.4f}")
                break

        # Save states
        torch.save({'epoch': epoch, 'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict(), 'loss': epoch_loss}, checkpoint_path)

    # Now reload best checkpoint for future use
    print(f"Currently loading best model available")
    best_checkpoint = torch.load(best_model_path, map_location=device)
    model.load_state_dict(best_checkpoint['model_state_dict'])

    # ----------------< CM Module >-------------------------------------------------------------------------------------
    model.eval()
    all_preds, all_labels = [], []
    with torch.no_grad():
        for inputs, labels in test_loader:
            inputs, labels = inputs.to(device), labels.to(device)  # Changed from .to("cuda")
            outputs = model(inputs)
            all_preds.append(torch.argmax(outputs, dim=1).cpu().numpy())
            all_labels.append(labels.cpu().numpy())

    cm = confusion_matrix(np.concatenate(all_labels), np.concatenate(all_preds))
    cm_percent = cm.astype(float) / cm.sum(axis=1, keepdims=True) * 100

    plt.figure(figsize=(10, 8))
    sns.heatmap(cm_percent, annot=True, fmt=".1f", cmap="Blues", xticklabels=class_names, yticklabels=class_names)
    plt.title(f"Confusion Matrix ({len(class_names)} Classes)")
    plt.ylabel('True Label')
    plt.xlabel('Predicted Label')
    plt.show()

    # ----------------< Grad-CAM Module >-----------------------------------------------------------------------------------
    indices = range(len(test_dataset) - 25, len(test_dataset))
    all_visualizations = []

    cam_extractor = SmoothGradCAMpp(model, target_layer='features.denseblock4')
    model.eval()

    for i, idx in enumerate(indices):
        img_path, _ = test_dataset.samples[idx]
        original_pil = Image.open(img_path).convert("RGB")
        viz_original = original_pil.resize((256, 256))  # Match new transform size
        input_tensor = val_transform(original_pil).unsqueeze(0).to(device)  # Changed from .cuda()

        out = model(input_tensor)
        probs = F.softmax(out, dim=1)
        conf, pred_idx = torch.max(probs, dim=1)
        pred_class = test_dataset.classes[pred_idx.item()]

        act_map = cam_extractor(pred_idx.item(), out)

        # Simple color map fallback if class missing
        color_map = {'normal': 'Purples', 'mass': 'jet', 'effusion': 'plasma', 'edema': 'gnuplot2', 'atelectasis': 'viridis'}
        cmap = color_map.get(pred_class, 'jet')

        result_pil = overlay_mask(
            viz_original,
            to_pil_image(act_map[0].squeeze(0), mode='F'),
            alpha=0.5,
            colormap=cmap
        )
        combined = np.hstack((np.array(viz_original), np.array(result_pil)))
        all_visualizations.append((combined, f"Pred: {pred_class} ({conf.item():.2%})"))

    # Visualization Plot
    fig, axes = plt.subplots(5, 5, figsize=(20, 20))
    axes = axes.flatten()
    for idx, (img, title) in enumerate(all_visualizations):
        axes[idx].imshow(img)
        axes[idx].set_title(title, fontsize=10)
        axes[idx].axis('off')

    plt.tight_layout()
    plt.show()
    cam_extractor.remove_hooks()
    print(f"Finished in {(time.time() - start_time) / 60:.2f} minutes")

if __name__ == '__main__': main()
